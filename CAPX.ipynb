{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM3W3bw5zSsVPd5wbPSTT8w",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pavani-Jyothirmai/Stock-Prediction-Project/blob/main/CAPX.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Stock Movement Analysis Based on Social Media Sentiment**"
      ],
      "metadata": {
        "id": "TcsErXX7bn-N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install praw pandas\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYdbjigrFgpu",
        "outputId": "e7a8e5f1-3d76-419d-946c-192fde364ed6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting praw\n",
            "  Downloading praw-7.8.1-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Collecting prawcore<3,>=2.4 (from praw)\n",
            "  Downloading prawcore-2.4.0-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting update_checker>=0.18 (from praw)\n",
            "  Downloading update_checker-0.18.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: websocket-client>=0.54.0 in /usr/local/lib/python3.10/dist-packages (from praw) (1.8.0)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: requests<3.0,>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from prawcore<3,>=2.4->praw) (2.32.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (2024.8.30)\n",
            "Downloading praw-7.8.1-py3-none-any.whl (189 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m189.3/189.3 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading prawcore-2.4.0-py3-none-any.whl (17 kB)\n",
            "Downloading update_checker-0.18.0-py3-none-any.whl (7.0 kB)\n",
            "Installing collected packages: update_checker, prawcore, praw\n",
            "Successfully installed praw-7.8.1 prawcore-2.4.0 update_checker-0.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Scrapping**"
      ],
      "metadata": {
        "id": "AT25LB0yNNRb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import praw\n",
        "import pandas as pd\n",
        "import requests\n",
        "from textblob import TextBlob\n",
        "\n",
        "# Step 1: Reddit API credentials\n",
        "CLIENT_ID = 'aRUMjsRkJ-mqKAtdvyJqYw'\n",
        "CLIENT_SECRET = 'Ue2IVDlmbAIn_ZZeitMMigBxIJKMgA'\n",
        "USER_AGENT = 'StockScraper by /u/Fuzzy_Tie6180'\n",
        "\n",
        "# Step 2: Authenticate with Reddit API\n",
        "reddit = praw.Reddit(\n",
        "    client_id=CLIENT_ID,\n",
        "    client_secret=CLIENT_SECRET,\n",
        "    user_agent=USER_AGENT\n",
        ")\n",
        "\n",
        "# Step 3: Subreddits and keywords\n",
        "subreddits = [\"StockMarket\", \"WallStreetBets\", \"Investing\", \"personalfinance\", \"financialindependence\"]\n",
        "keywords = [\"AAPL\", \"TSLA\", \"GOOG\", \"AMZN\", \"MSFT\", \"stock market\", \"investing\", \"cryptostocks\", \"dividends\", \"options\", \"tech stocks\", \"EV stocks\", \"short squeeze\"]\n",
        "\n",
        "# Step 4: Fetch posts from Reddit API\n",
        "def fetch_reddit_data(subreddits, keywords, post_limit=1000):\n",
        "    posts = []\n",
        "    for subreddit in subreddits:\n",
        "        for sort_option in [\"hot\", \"top\", \"new\"]:  # Fetch posts from hot, top, and new categories\n",
        "            submissions = getattr(reddit.subreddit(subreddit), sort_option)(limit=post_limit)\n",
        "            for submission in submissions:\n",
        "                if any(keyword.lower() in submission.title.lower() for keyword in keywords):\n",
        "                    sentiment = TextBlob(submission.title).sentiment\n",
        "                    posts.append({\n",
        "                        'Subreddit': subreddit,\n",
        "                        'Sort': sort_option,  # Indicate which sort type was used\n",
        "                        'Title': submission.title,\n",
        "                        'Author': submission.author.name if submission.author else None,\n",
        "                        'Score': submission.score,\n",
        "                        'Upvote Ratio': submission.upvote_ratio,\n",
        "                        'Comments': submission.num_comments,\n",
        "                        'Created At': submission.created_utc,\n",
        "                        'Post URL': submission.url,\n",
        "                        'Sentiment Polarity': sentiment.polarity,\n",
        "                        'Sentiment Subjectivity': sentiment.subjectivity\n",
        "                    })\n",
        "    return posts\n",
        "\n",
        "# Step 5: Fetch historical data using Pushshift API\n",
        "def fetch_pushshift_data(subreddit, keywords, start_time, end_time, limit=1000):\n",
        "    base_url = \"https://api.pushshift.io/reddit/search/submission/\"\n",
        "    posts = []\n",
        "    for keyword in keywords:\n",
        "        params = {\n",
        "            \"subreddit\": subreddit,\n",
        "            \"q\": keyword,\n",
        "            \"after\": start_time,\n",
        "            \"before\": end_time,\n",
        "            \"size\": limit\n",
        "        }\n",
        "        response = requests.get(base_url, params=params)\n",
        "        if response.status_code == 200:\n",
        "            data = response.json().get(\"data\", [])\n",
        "            for post in data:\n",
        "                posts.append({\n",
        "                    'Subreddit': subreddit,\n",
        "                    'Title': post.get('title', ''),\n",
        "                    'Author': post.get('author', ''),\n",
        "                    'Score': post.get('score', 0),\n",
        "                    'Comments': post.get('num_comments', 0),\n",
        "                    'Created At': post.get('created_utc', 0),\n",
        "                    'Post URL': post.get('full_link', ''),\n",
        "                })\n",
        "    return posts\n",
        "\n",
        "# Step 6: Fetch data and save to CSV\n",
        "def main():\n",
        "    print(\"Fetching data from Reddit API and Pushshift...\")\n",
        "\n",
        "    # Fetch posts from Reddit API\n",
        "    reddit_data = fetch_reddit_data(subreddits, keywords, post_limit=500)\n",
        "\n",
        "    # Fetch historical data from Pushshift\n",
        "    start_time = \"1672531200\"  # Unix timestamp for January 1, 2023\n",
        "    end_time = \"1704067200\"    # Unix timestamp for January 1, 2024\n",
        "    pushshift_data = []\n",
        "    for subreddit in subreddits:\n",
        "        pushshift_data.extend(fetch_pushshift_data(subreddit, keywords, start_time, end_time, limit=500))\n",
        "\n",
        "    # Combine both datasets\n",
        "    all_posts = reddit_data + pushshift_data\n",
        "\n",
        "    if all_posts:\n",
        "        df = pd.DataFrame(all_posts)\n",
        "        df['Created At'] = pd.to_datetime(df['Created At'], unit='s')  # Convert timestamps to datetime\n",
        "        df.to_csv(\"reddit.csv\", index=False)\n",
        "        print(\"Data saved to 'reddit.csv'.\")\n",
        "    else:\n",
        "        print(\"No relevant posts found.\")\n",
        "\n",
        "# Run the script\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oY5-n0iAK5vs",
        "outputId": "7717eb70-a1a0-482c-cc59-60e9e47fb0b8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetching data from Reddit API and Pushshift...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data saved to 'reddit.csv'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Pre-Processing**"
      ],
      "metadata": {
        "id": "PJ8UrAevNQtH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NlsijZkxOpLX",
        "outputId": "2e76a9b6-f018-41a5-ad98-522ee70da954"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# 1. Load the Reddit data\n",
        "df = pd.read_csv(\"/content/reddit.csv\")\n",
        "\n",
        "# 2. Handle Missing Data using Imputation\n",
        "df['Score'] = df['Score'].fillna(df['Score'].mean())  # Fill missing Score with mean\n",
        "df['Comments'] = df['Comments'].fillna(df['Comments'].mean())  # Fill missing Comments with mean\n",
        "\n",
        "# For Upvote Ratio, use forward fill\n",
        "df['Upvote Ratio'] = df['Upvote Ratio'].ffill()  # Forward fill for Upvote Ratio\n",
        "\n",
        "# Handle missing sentiment values by filling them with the median\n",
        "df['Sentiment Polarity'] = df['Sentiment Polarity'].fillna(df['Sentiment Polarity'].median())\n",
        "df['Sentiment Subjectivity'] = df['Sentiment Subjectivity'].fillna(df['Sentiment Subjectivity'].median())\n",
        "\n",
        "# 3. Replace Sentiment Polarity and Sentiment Subjectivity values of 0 with the mean\n",
        "mean_sentiment_polarity = df['Sentiment Polarity'].mean()\n",
        "mean_sentiment_subjectivity = df['Sentiment Subjectivity'].mean()\n",
        "\n",
        "df['Sentiment Polarity'] = df['Sentiment Polarity'].replace(0, mean_sentiment_polarity)\n",
        "df['Sentiment Subjectivity'] = df['Sentiment Subjectivity'].replace(0, mean_sentiment_subjectivity)\n",
        "\n",
        "# 4. Clean text function to remove URLs, special characters, and make text lowercase\n",
        "def clean_text(text):\n",
        "    if isinstance(text, str):  # Check if the input is a string\n",
        "        text = re.sub(r'http\\S+', '', text)  # Remove URLs\n",
        "        text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Remove non-alphabetic characters\n",
        "        text = text.lower()  # Convert to lowercase\n",
        "    return text\n",
        "\n",
        "df['Cleaned Title'] = df['Title'].apply(clean_text)\n",
        "\n",
        "# 5. Tokenization and optional short word removal\n",
        "def preprocess_text(text):\n",
        "    if isinstance(text, str):  # Ensure the text is a string\n",
        "        # Tokenize the text into words (split by spaces)\n",
        "        words = text.split()\n",
        "\n",
        "        # Remove short words\n",
        "        words = [word for word in words if len(word) > 2]\n",
        "\n",
        "        return ' '.join(words)\n",
        "    else:\n",
        "        return ''\n",
        "\n",
        "df['Processed Title'] = df['Cleaned Title'].apply(preprocess_text)\n",
        "\n",
        "# 6. Vectorization: Convert text into numerical features using TF-IDF\n",
        "tfidf = TfidfVectorizer(max_features=5000)  # Limit to top 5000 features to avoid overfitting\n",
        "X_text = tfidf.fit_transform(df['Processed Title']).toarray()\n",
        "\n",
        "# 7. Combine numerical features: Combine TF-IDF features with sentiment scores\n",
        "X_combined = np.hstack([X_text, df[['Sentiment Polarity', 'Sentiment Subjectivity']].values])\n",
        "\n",
        "# 8. Feature Scaling: Normalize the features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_combined)\n",
        "\n",
        "# Final preprocessed data ready for model input\n",
        "print(\"Preprocessing completed. Data ready for model input.\")\n",
        "\n",
        "# Save the cleaned dataframe if you want to examine it\n",
        "df.to_csv(\"cleaned_reddit_data.csv\", index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1XwMGUSwREj3",
        "outputId": "797ff21e-b413-4119-c5f5-46e5d8a1e322"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessing completed. Data ready for model input.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bVGYTeX4fBY",
        "outputId": "f7962b15-ad6a-426a-a676-f2f373ab1d50"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Subreddit Sort                                              Title  \\\n",
            "0  StockMarket  hot  As an european do you buy only from EU stock m...   \n",
            "1  StockMarket  hot  I know it’s not much, but I took my first step...   \n",
            "2  StockMarket  hot                    Investing in AI infrastructure?   \n",
            "3  StockMarket  hot  Starting My Investing Journey as an 18-Year-Ol...   \n",
            "4  StockMarket  hot  BofA raises 2025 year-end S&P 500 target to 66...   \n",
            "\n",
            "                Author  Score  Upvote Ratio  Comments           Created At  \\\n",
            "0        Christs_Elite      0          0.46        13  2024-12-07 01:42:18   \n",
            "1  General_Thought8412    600          0.95        65  2024-12-04 18:07:27   \n",
            "2      Typical-Ad-4591     15          0.79        25  2024-11-28 20:07:41   \n",
            "3    Jayso_Productions      0          0.45        11  2024-11-27 21:03:44   \n",
            "4        z34conversion     18          0.83        12  2024-11-26 21:56:01   \n",
            "\n",
            "                                            Post URL  Sentiment Polarity  \\\n",
            "0  https://www.reddit.com/r/StockMarket/comments/...            0.063545   \n",
            "1             https://www.reddit.com/gallery/1h6mqn4            0.106250   \n",
            "2  https://www.reddit.com/r/StockMarket/comments/...            0.063545   \n",
            "3  https://www.reddit.com/r/StockMarket/comments/...            0.063545   \n",
            "4  https://www.investing.com/news/stock-market-ne...            0.063545   \n",
            "\n",
            "   Sentiment Subjectivity                                      Cleaned Title  \\\n",
            "0                0.500000  as an european do you buy only from eu stock m...   \n",
            "1                0.266667  i know its not much but i took my first step i...   \n",
            "2                0.232140                     investing in ai infrastructure   \n",
            "3                0.100000  starting my investing journey as an yearold  n...   \n",
            "4                0.232140  bofa raises  yearend sp  target to  by investi...   \n",
            "\n",
            "                                     Processed Title  VADER Sentiment  \\\n",
            "0       european you buy only from stock market ibis         0.090963   \n",
            "1  know its not much but took first step into inv...         0.090963   \n",
            "2                           investing infrastructure         0.000000   \n",
            "3  starting investing journey yearold need your a...         0.000000   \n",
            "4            bofa raises yearend target investingcom         0.000000   \n",
            "\n",
            "  Sentiment Category  Stock Movement  \n",
            "0           Positive               1  \n",
            "1           Positive               1  \n",
            "2            Neutral               0  \n",
            "3            Neutral               0  \n",
            "4            Neutral               0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Data Analysis(Sentiment Analysis)**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zMOOAJLrZrT0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "import random\n",
        "\n",
        "# Load the cleaned Reddit data\n",
        "df = pd.read_csv(\"cleaned_reddit_data.csv\")\n",
        "\n",
        "# Initialize the VADER SentimentIntensityAnalyzer\n",
        "sia = SentimentIntensityAnalyzer()\n",
        "\n",
        "# Function to get VADER Sentiment (compound score)\n",
        "def get_vader_sentiment(text):\n",
        "    if isinstance(text, str):\n",
        "        sentiment_score = sia.polarity_scores(text)  # Get VADER sentiment scores\n",
        "        return sentiment_score['compound']  # Return the compound score\n",
        "    return 0  # Default to 0 if the text is not a string\n",
        "\n",
        "# Apply the VADER sentiment analysis to the \"Processed Title\" column\n",
        "df['VADER Sentiment'] = df['Processed Title'].apply(get_vader_sentiment)\n",
        "\n",
        "# 1. Calculate the mean or median of the VADER Sentiment column\n",
        "mean_sentiment_polarity = df['VADER Sentiment'].mean()  # Calculate the mean\n",
        "median_sentiment_polarity = df['VADER Sentiment'].median()  # Calculate the median\n",
        "\n",
        "# 2. Randomly replace a portion of `0` values with the mean or median\n",
        "def replace_zeros_with_random_mean_or_median(sentiment_value, mean_value, median_value, replace_probability=0.5):\n",
        "    if sentiment_value == 0:  # If the sentiment value is 0\n",
        "        # Randomly decide whether to replace with mean or median\n",
        "        if random.random() < replace_probability:\n",
        "            return mean_value  # Replace with mean value\n",
        "        else:\n",
        "            return median_value  # Replace with median value\n",
        "    else:\n",
        "        return sentiment_value  # Keep non-zero values as is\n",
        "\n",
        "# Apply the replacement function to the VADER Sentiment column\n",
        "df['VADER Sentiment'] = df['VADER Sentiment'].apply(\n",
        "    lambda x: replace_zeros_with_random_mean_or_median(x, mean_sentiment_polarity, median_sentiment_polarity)\n",
        ")\n",
        "\n",
        "# 3. Sentiment classification based on the updated compound score\n",
        "def classify_sentiment(compound_score):\n",
        "    if compound_score > 0.01:  # Positive sentiment threshold\n",
        "        return 'Positive'\n",
        "    elif compound_score < -0.01:  # Negative sentiment threshold\n",
        "        return 'Negative'\n",
        "    else:\n",
        "        return 'Neutral'\n",
        "\n",
        "# Apply sentiment classification based on the updated compound score\n",
        "df['Sentiment Category'] = df['VADER Sentiment'].apply(classify_sentiment)\n",
        "\n",
        "# 4. Create the Stock Movement column based on sentiment classification\n",
        "# - 1 (up) for positive sentiment\n",
        "# - 0 (down) for negative or neutral sentiment\n",
        "df['Stock Movement'] = df['Sentiment Category'].apply(lambda x: 1 if x == 'Positive' else 0)\n",
        "\n",
        "# Show sentiment analysis result and stock movement\n",
        "print(\"Sentiment Analysis (VADER):\")\n",
        "print(df[['Title', 'VADER Sentiment', 'Sentiment Category', 'Stock Movement']].head())\n",
        "\n",
        "# Save the data with updated sentiment values and stock movement predictions\n",
        "df.to_csv('processed_reddit_data_with_sentiment.csv', index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ehz4NtK3REnW",
        "outputId": "786333fa-9ff3-4d43-bc0d-1ef7e51b8f38"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiment Analysis (VADER):\n",
            "                                               Title  VADER Sentiment  \\\n",
            "0  As an european do you buy only from EU stock m...         0.000000   \n",
            "1  I know it’s not much, but I took my first step...         0.090963   \n",
            "2                    Investing in AI infrastructure?         0.000000   \n",
            "3  Starting My Investing Journey as an 18-Year-Ol...         0.090963   \n",
            "4  BofA raises 2025 year-end S&P 500 target to 66...         0.090963   \n",
            "\n",
            "  Sentiment Category  Stock Movement  \n",
            "0            Neutral               0  \n",
            "1           Positive               1  \n",
            "2            Neutral               0  \n",
            "3           Positive               1  \n",
            "4           Positive               1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model Prediction**"
      ],
      "metadata": {
        "id": "dMEzqL44Zm-K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the data with different models"
      ],
      "metadata": {
        "id": "FIU3MinmwJIS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LogisticRegression**"
      ],
      "metadata": {
        "id": "4OjVMn_cZ2qw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# 1. Feature Extraction: TF-IDF for text data\n",
        "tfidf = TfidfVectorizer(max_features=5000)\n",
        "X_text = tfidf.fit_transform(df['Processed Title']).toarray()\n",
        "\n",
        "# 2. Combine the text data with other numerical features (Sentiment scores)\n",
        "X_combined = np.hstack([X_text, df[['VADER Sentiment']].values])\n",
        "\n",
        "# 3. Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_combined)\n",
        "\n",
        "# 4. Target Variable: Stock Movement (1 for up, 0 for down)\n",
        "y = df['Stock Movement']\n",
        "\n",
        "# 5. Train-Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 6. Machine Learning Model: Logistic Regression\n",
        "model = LogisticRegression(random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 7. Predictions and Evaluation\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# 8. Evaluation Metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "# 9. Print Evaluation Results\n",
        "print(\"Model Evaluation:\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "\n",
        "# 10. Combine Actual and Predicted Values for Display\n",
        "predicted_df = pd.DataFrame({\n",
        "    'Actual Stock Movement': y_test,\n",
        "    'Predicted Stock Movement': y_pred\n",
        "})\n",
        "\n",
        "# Print the predicted stock movements\n",
        "print(\"\\nPredicted Stock Movements:\")\n",
        "print(predicted_df.head())  # Display the first 5 predictions\n",
        "\n",
        "print(\"\\nModel evaluation completed.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gMYbSMP5X-Qu",
        "outputId": "67d7426e-f495-4b36-d697-47eebf860f5c"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Evaluation:\n",
            "Accuracy: 0.8272\n",
            "Precision: 0.8491\n",
            "Recall: 0.8824\n",
            "F1 Score: 0.8654\n",
            "\n",
            "Predicted Stock Movements:\n",
            "     Actual Stock Movement  Predicted Stock Movement\n",
            "70                       1                         1\n",
            "281                      1                         0\n",
            "283                      0                         1\n",
            "33                       1                         1\n",
            "42                       1                         1\n",
            "\n",
            "Model evaluation completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Support Vector Machine (SVM)**"
      ],
      "metadata": {
        "id": "cuVFy59oaf1t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# 1. Feature Extraction: TF-IDF for text data\n",
        "tfidf = TfidfVectorizer(max_features=5000)\n",
        "X_text = tfidf.fit_transform(df['Processed Title']).toarray()\n",
        "\n",
        "# 2. Combine the text data with other numerical features (Sentiment scores)\n",
        "X_combined = np.hstack([X_text, df[['VADER Sentiment']].values])\n",
        "\n",
        "# 3. Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_combined)\n",
        "\n",
        "# 4. Target Variable: Stock Movement (1 for up, 0 for down)\n",
        "y = df['Stock Movement']\n",
        "\n",
        "# 5. Train-Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 6. Machine Learning Model: Support Vector Machine (SVM)\n",
        "model = SVC(random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 7. Predictions and Evaluation\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# 8. Evaluation Metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "# 9. Print Evaluation Results\n",
        "print(\"Model Evaluation:\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "\n",
        "# 10. Combine Actual and Predicted Values for Display\n",
        "predicted_df = pd.DataFrame({\n",
        "    'Actual Stock Movement': y_test,\n",
        "    'Predicted Stock Movement': y_pred\n",
        "})\n",
        "\n",
        "# Print the predicted stock movements\n",
        "print(\"\\nPredicted Stock Movements:\")\n",
        "print(predicted_df.head())  # Display the first 5 predictions\n",
        "\n",
        "print(\"\\nModel evaluation completed.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZwxPaLvfaceE",
        "outputId": "d2dac6ea-329a-4fa0-b53f-95818b75c9a4"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Evaluation:\n",
            "Accuracy: 0.6790\n",
            "Precision: 0.6866\n",
            "Recall: 0.9020\n",
            "F1 Score: 0.7797\n",
            "\n",
            "Predicted Stock Movements:\n",
            "     Actual Stock Movement  Predicted Stock Movement\n",
            "70                       1                         1\n",
            "281                      1                         0\n",
            "283                      0                         1\n",
            "33                       1                         1\n",
            "42                       1                         1\n",
            "\n",
            "Model evaluation completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Naive Bayes Classifier**"
      ],
      "metadata": {
        "id": "byqFhaL1avrX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# 1. Feature Extraction: TF-IDF for text data\n",
        "tfidf = TfidfVectorizer(max_features=5000)\n",
        "X_text = tfidf.fit_transform(df['Processed Title']).toarray()\n",
        "\n",
        "# 2. Target Variable: Stock Movement (1 for up, 0 for down)\n",
        "y = df['Stock Movement']\n",
        "\n",
        "# 3. Train-Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_text, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 4. Machine Learning Model: Naive Bayes\n",
        "model = MultinomialNB()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 5. Predictions and Evaluation\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# 6. Evaluation Metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "# 7. Print Evaluation Results\n",
        "print(\"Model Evaluation:\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "\n",
        "# 8. Combine Actual and Predicted Values for Display\n",
        "predicted_df = pd.DataFrame({\n",
        "    'Actual Stock Movement': y_test,\n",
        "    'Predicted Stock Movement': y_pred\n",
        "})\n",
        "\n",
        "# Print the predicted stock movements\n",
        "print(\"\\nPredicted Stock Movements:\")\n",
        "print(predicted_df.head())  # Display the first 5 predictions\n",
        "\n",
        "print(\"\\nModel evaluation completed.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjZlH_Ebacj7",
        "outputId": "ec20ef60-d940-49c6-a64f-62bffda9cab0"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Evaluation:\n",
            "Accuracy: 0.7407\n",
            "Precision: 0.7500\n",
            "Recall: 0.8824\n",
            "F1 Score: 0.8108\n",
            "\n",
            "Predicted Stock Movements:\n",
            "     Actual Stock Movement  Predicted Stock Movement\n",
            "70                       1                         1\n",
            "281                      1                         1\n",
            "283                      0                         1\n",
            "33                       1                         1\n",
            "42                       1                         1\n",
            "\n",
            "Model evaluation completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Decision Tree Classifier**"
      ],
      "metadata": {
        "id": "cf81gMmLamT3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# 1. Feature Extraction: TF-IDF for text data\n",
        "tfidf = TfidfVectorizer(max_features=5000)\n",
        "X_text = tfidf.fit_transform(df['Processed Title']).toarray()\n",
        "\n",
        "# 2. Combine the text data with other numerical features (Sentiment scores)\n",
        "X_combined = np.hstack([X_text, df[['VADER Sentiment']].values])\n",
        "\n",
        "# 3. Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_combined)\n",
        "\n",
        "# 4. Target Variable: Stock Movement (1 for up, 0 for down)\n",
        "y = df['Stock Movement']\n",
        "\n",
        "# 5. Train-Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 6. Machine Learning Model: Decision Tree Classifier\n",
        "model = DecisionTreeClassifier(random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 7. Predictions and Evaluation\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# 8. Evaluation Metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "# 9. Print Evaluation Results\n",
        "print(\"Model Evaluation:\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "\n",
        "# 10. Combine Actual and Predicted Values for Display\n",
        "predicted_df = pd.DataFrame({\n",
        "    'Actual Stock Movement': y_test,\n",
        "    'Predicted Stock Movement': y_pred\n",
        "})\n",
        "\n",
        "# Print the predicted stock movements\n",
        "print(\"\\nPredicted Stock Movements:\")\n",
        "print(predicted_df.head())  # Display the first 5 predictions\n",
        "\n",
        "print(\"\\nModel evaluation completed.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71o6VWXbacgg",
        "outputId": "ecfbcb9b-efaa-40b9-a932-5654033d8b69"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Evaluation:\n",
            "Accuracy: 1.0000\n",
            "Precision: 1.0000\n",
            "Recall: 1.0000\n",
            "F1 Score: 1.0000\n",
            "\n",
            "Predicted Stock Movements:\n",
            "     Actual Stock Movement  Predicted Stock Movement\n",
            "70                       1                         1\n",
            "281                      1                         1\n",
            "283                      0                         0\n",
            "33                       1                         1\n",
            "42                       1                         1\n",
            "\n",
            "Model evaluation completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**RandomForestClassifier**"
      ],
      "metadata": {
        "id": "LI_aqIVnzbc6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import joblib\n",
        "\n",
        "\n",
        "# 1. Feature Extraction: TF-IDF for text data\n",
        "tfidf = TfidfVectorizer(max_features=5000)\n",
        "X_text = tfidf.fit_transform(df['Processed Title']).toarray()\n",
        "\n",
        "# 2. Combine the text data with other numerical features (Sentiment scores)\n",
        "X_combined = np.hstack([X_text, df[['VADER Sentiment']].values])\n",
        "\n",
        "# 3. Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_combined)\n",
        "\n",
        "# 4. Target Variable: Stock Movement (1 for up, 0 for down)\n",
        "y = df['Stock Movement']\n",
        "\n",
        "# 5. Train-Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 6. Machine Learning Model: Random Forest Classifier\n",
        "model = RandomForestClassifier(random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 7. Predictions and Evaluation\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# 8. Evaluation Metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "# 9. Print Evaluation Results\n",
        "print(\"Model Evaluation:\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "\n",
        "# 10. Combine Actual and Predicted Values for Display\n",
        "predicted_df = pd.DataFrame({\n",
        "    'Actual Stock Movement': y_test,\n",
        "    'Predicted Stock Movement': y_pred\n",
        "})\n",
        "\n",
        "# Print the predicted stock movements\n",
        "print(\"\\nPredicted Stock Movements:\")\n",
        "print(predicted_df.head())  # Display the first 5 predictions\n",
        "\n",
        "# 11. Save Model and Results\n",
        "# Save the trained model\n",
        "joblib.dump(model, 'stock_movement_model.pkl')\n",
        "\n",
        "# Save the test data predictions\n",
        "test_results = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\n",
        "test_results.to_csv('test_predictions.csv', index=False)\n",
        "\n",
        "# Save the processed data with sentiment results\n",
        "df.to_csv('processed_reddit_data_with_sentiment.csv', index=False)\n",
        "\n",
        "# Save the predictions to a CSV file\n",
        "predicted_df.to_csv('predicted_stock_movements.csv', index=False)\n",
        "\n",
        "print(\"\\nModel and results saved.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "snBdmpYpZVJD",
        "outputId": "e55a37dc-dc48-409d-da7d-e9efb0773a6b"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Evaluation:\n",
            "Accuracy: 1.0000\n",
            "Precision: 1.0000\n",
            "Recall: 1.0000\n",
            "F1 Score: 1.0000\n",
            "\n",
            "Predicted Stock Movements:\n",
            "     Actual Stock Movement  Predicted Stock Movement\n",
            "70                       1                         1\n",
            "281                      1                         1\n",
            "283                      0                         0\n",
            "33                       1                         1\n",
            "42                       1                         1\n",
            "\n",
            "Model and results saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "# Generate Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Display the Confusion Matrix using Seaborn's heatmap\n",
        "plt.figure(figsize=(6, 6))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False,\n",
        "            xticklabels=['Down', 'Up'], yticklabels=['Down', 'Up'])\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "oiyEV2imzp3s",
        "outputId": "6ab2634d-1215-490d-e686-3f6df8a5d43f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Test Dataset Generation**"
      ],
      "metadata": {
        "id": "Tl2HNGVyvEzC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import praw\n",
        "import pandas as pd\n",
        "\n",
        "# Initialize PRAW with your Reddit API credentials\n",
        "reddit = praw.Reddit(client_id='aRUMjsRkJ-mqKAtdvyJqYw',\n",
        "                     client_secret='Ue2IVDlmbAIn_ZZeitMMigBxIJKMgA',\n",
        "                     user_agent='StockScrapper by /u/Fuzzy_Tie6180')\n",
        "\n",
        "# Fetch the top 100 posts from the 'stocks' subreddit\n",
        "subreddit = reddit.subreddit('stocks')\n",
        "posts = subreddit.top('day', limit=100)  # Fetch the top posts of the day\n",
        "\n",
        "# Create a list to store post data\n",
        "post_data = []\n",
        "for post in posts:\n",
        "    post_data.append({\n",
        "        'title': post.title,\n",
        "        'score': post.score,\n",
        "        'url': post.url,\n",
        "        'created_utc': post.created_utc,\n",
        "        'comments': post.num_comments\n",
        "    })\n",
        "\n",
        "# Convert the list of posts into a DataFrame\n",
        "df_new = pd.DataFrame(post_data)\n",
        "\n",
        "# Save the new data to a CSV file for later use\n",
        "df_new.to_csv('new_reddit_data.csv', index=False)\n",
        "\n",
        "print(\"New Reddit data collected and saved.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m2VbQG26fw3k",
        "outputId": "70fe3e03-29a1-4b6a-c020-6fd5cbf50b8f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-2ace9b3bc755>:11: DeprecationWarning: Positional arguments for 'BaseListingMixin.top' will no longer be supported in PRAW 8.\n",
            "Call this function with 'time_filter' as a keyword argument.\n",
            "  posts = subreddit.top('day', limit=100)  # Fetch the top posts of the day\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New Reddit data collected and saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Use Random Forest**"
      ],
      "metadata": {
        "id": "afr24vV2viy2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import joblib\n",
        "\n",
        "# 1. Feature Extraction: TF-IDF for text data\n",
        "tfidf = TfidfVectorizer(max_features=5000)\n",
        "X_text = tfidf.fit_transform(df['Processed Title']).toarray()\n",
        "\n",
        "# 2. Combine the text data with other numerical features (Sentiment scores)\n",
        "X_combined = np.hstack([X_text, df[['VADER Sentiment']].values])\n",
        "\n",
        "# 3. Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_combined)\n",
        "\n",
        "# 4. Target Variable: Stock Movement (1 for up, 0 for down)\n",
        "y = df['Stock Movement']\n",
        "\n",
        "# 5. Train-Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 6. Random Forest Model with Hyperparameter Tuning\n",
        "param_dist = {\n",
        "    'n_estimators': [50, 100, 200],  # Number of trees\n",
        "    'max_depth': [3, 5, 10, 20, None],  # Limit tree depth\n",
        "    'min_samples_split': [2, 5, 10],  # Minimum samples to split a node\n",
        "    'min_samples_leaf': [1, 2, 4],  # Minimum samples per leaf\n",
        "    'max_features': ['sqrt', 'log2', None]  # Features to consider for splitting\n",
        "}\n",
        "\n",
        "# Hyperparameter optimization\n",
        "random_search = RandomizedSearchCV(\n",
        "    RandomForestClassifier(random_state=42),\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=10,\n",
        "    cv=5,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# 7. Best parameters and model training\n",
        "print(\"Best parameters from RandomizedSearchCV:\")\n",
        "print(random_search.best_params_)\n",
        "\n",
        "model = random_search.best_estimator_\n",
        "\n",
        "# 8. Predictions and Evaluation\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# 9. Evaluation Metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(\"\\nModel Evaluation:\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "\n",
        "# 10. Classification Report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# 11. Cross-Validation Scores\n",
        "cross_val_scores = cross_val_score(model, X_scaled, y, cv=5, scoring='accuracy')\n",
        "print(f\"\\nCross-validation scores: {cross_val_scores}\")\n",
        "print(f\"Average cross-validated accuracy: {np.mean(cross_val_scores):.4f}\")\n",
        "\n",
        "# 12. Combine Actual and Predicted Values for Display\n",
        "predicted_df = pd.DataFrame({\n",
        "    'Actual Stock Movement': y_test,\n",
        "    'Predicted Stock Movement': y_pred\n",
        "})\n",
        "\n",
        "print(\"\\nPredicted Stock Movements:\")\n",
        "print(predicted_df.head())  # Display the first 5 predictions\n",
        "\n",
        "# 13. Save the Model and Related Objects\n",
        "joblib.dump(model, 'random_forest_stock_movement_model.pkl')\n",
        "joblib.dump(tfidf, 'tfidf_vectorizer.pkl')\n",
        "joblib.dump(scaler, 'scaler.pkl')\n",
        "\n",
        "print(\"\\nModel evaluation completed.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ztzKqG2ixkI",
        "outputId": "ee3615f5-7fd3-4ac8-b729-11e2579dfa40"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/ma/core.py:2820: RuntimeWarning: invalid value encountered in cast\n",
            "  _data = np.array(data, dtype=dtype, copy=copy,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters from RandomizedSearchCV:\n",
            "{'n_estimators': 100, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': None, 'max_depth': 3}\n",
            "\n",
            "Model Evaluation:\n",
            "Accuracy: 1.0000\n",
            "Precision: 1.0000\n",
            "Recall: 1.0000\n",
            "F1 Score: 1.0000\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        26\n",
            "           1       1.00      1.00      1.00        55\n",
            "\n",
            "    accuracy                           1.00        81\n",
            "   macro avg       1.00      1.00      1.00        81\n",
            "weighted avg       1.00      1.00      1.00        81\n",
            "\n",
            "\n",
            "Cross-validation scores: [1. 1. 1. 1. 1.]\n",
            "Average cross-validated accuracy: 1.0000\n",
            "\n",
            "Predicted Stock Movements:\n",
            "     Actual Stock Movement  Predicted Stock Movement\n",
            "70                       1                         1\n",
            "281                      0                         0\n",
            "283                      0                         0\n",
            "33                       1                         1\n",
            "42                       1                         1\n",
            "\n",
            "Model evaluation completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Predicting Stock Movements On Test Dataset"
      ],
      "metadata": {
        "id": "pinb50Kkvt94"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Load the preprocessed new Reddit data\n",
        "df_new = pd.read_csv('new_reddit_data.csv')\n",
        "\n",
        "# Perform Sentiment Analysis using VADER\n",
        "sia = SentimentIntensityAnalyzer()\n",
        "\n",
        "# Function to get VADER sentiment score\n",
        "def get_vader_sentiment(text):\n",
        "    if isinstance(text, str):\n",
        "        sentiment_score = sia.polarity_scores(text)\n",
        "        return sentiment_score['compound']  # Compound score gives the overall sentiment\n",
        "    return 0\n",
        "\n",
        "# Add VADER Sentiment to the DataFrame\n",
        "df_new['VADER Sentiment'] = df_new['title'].apply(get_vader_sentiment)\n",
        "\n",
        "# Adjust the sentiment threshold to determine stock movement\n",
        "df_new['Stock Movement'] = df_new['VADER Sentiment'].apply(lambda x: 1 if x > 0.2 else 0)  # You can adjust threshold as needed\n",
        "\n",
        "# Convert sentiment to Positive/Negative/Neutral for better understanding (optional)\n",
        "df_new['Sentiment Category'] = df_new['VADER Sentiment'].apply(\n",
        "    lambda x: 'Positive' if x > 0 else ('Negative' if x < 0 else 'Neutral'))\n",
        "\n",
        "# Load the saved TfidfVectorizer and StandardScaler\n",
        "tfidf = joblib.load('tfidf_vectorizer.pkl')\n",
        "scaler = joblib.load('scaler.pkl')\n",
        "\n",
        "# Feature Extraction: TF-IDF for text data (use the same vectorizer fitted on the training data)\n",
        "X_text_new = tfidf.transform(df_new['title']).toarray()  # Use transform instead of fit_transform\n",
        "\n",
        "# Combine the text data with sentiment scores (VADER Sentiment)\n",
        "X_combined_new = np.hstack([X_text_new, df_new[['VADER Sentiment']].values])\n",
        "\n",
        "# Standardize the features using the same scaler as during training\n",
        "X_scaled_new = scaler.transform(X_combined_new)  # Use transform instead of fit_transform\n",
        "# Load the trained model (you can replace 'decision_tree_stock_movement_model.pkl' with the model used in training)\n",
        "model = joblib.load('random_forest_stock_movement_model.pkl')  # Example: Replace with the model you trained\n",
        "\n",
        "# Make predictions on the new data\n",
        "y_pred_new = model.predict(X_scaled_new)\n",
        "\n",
        "# Combine Actual and Predicted Values for Display (if you have actual labels for the new data)\n",
        "predicted_df_new = pd.DataFrame({\n",
        "    'Title': df_new['title'],\n",
        "    'VADER Sentiment': df_new['VADER Sentiment'],\n",
        "    'Sentiment Category': df_new['Sentiment Category'],\n",
        "    'Predicted Stock Movement': y_pred_new\n",
        "})\n",
        "\n",
        "# Display the first few predictions\n",
        "print(\"\\nFirst few Predictions with Sentiment Analysis:\")\n",
        "print(predicted_df_new.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4MXf3igVynpB",
        "outputId": "e0ac0ccd-421c-45f7-9b02-c7c5a740ac57"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "First few Predictions with Sentiment Analysis:\n",
            "                                               Title  VADER Sentiment  \\\n",
            "0                        When do you take the money?           0.0000   \n",
            "1  Playing the TikTok possible ban (META, SNAP, G...          -0.4215   \n",
            "2                             Portfolio Wrapped 2024           0.0000   \n",
            "3  What is the investment thesis for the space se...           0.0000   \n",
            "4                Best strategy for investing in SPY:           0.6369   \n",
            "\n",
            "  Sentiment Category  Predicted Stock Movement  \n",
            "0            Neutral                         0  \n",
            "1           Negative                         0  \n",
            "2            Neutral                         0  \n",
            "3            Neutral                         0  \n",
            "4           Positive                         1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "# Calculate evaluation metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(\"Model Evaluation:\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-9i8OED0GcF",
        "outputId": "b76275b3-5488-46c4-9f26-0e237eea3ae5"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Evaluation:\n",
            "Accuracy: 1.0000\n",
            "Precision: 1.0000\n",
            "Recall: 1.0000\n",
            "F1 Score: 1.0000\n"
          ]
        }
      ]
    }
  ]
}